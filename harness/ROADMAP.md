# Claude Automation Harness - Implementation Roadmap

**Version:** 1.0
**Created:** 2026-01-27
**Status:** Phase 1 - Foundation Complete

## Implementation Status

### âœ… Phase 1: Foundation (COMPLETE)

**Goal:** Core infrastructure and basic loop mechanism

**Completed:**
- [x] Directory structure created
- [x] Main loop script (`loop.sh`) with logging and iteration control
- [x] Configuration system (`config.yaml`)
- [x] Bootstrap prompt template
- [x] Helper scripts (queue, interrupt, context, status)
- [x] Documentation (README, workflow guide)
- [x] Basic monitoring and reporting

**Deliverables:**
- Functional loop structure âœ…
- Work queue management âœ…
- Interrupt detection framework âœ…
- Context preservation system âœ…
- Status reporting âœ…

### âœ… Phase 2: Claude Code Integration (COMPLETE)

**Goal:** Actually spawn and manage Claude Code agents

**Completed:**
- [x] Researched Claude Code CLI invocation methods
- [x] Implemented complete agent spawning in `spawn_agent()`
- [x] Session lifecycle management (start, monitor, terminate)
- [x] Bootstrap prompt injection via `--append-system-prompt-file`
- [x] Real-time session output capture using stream-JSON
- [x] Session monitoring with heartbeat mechanism
- [x] Stall detection and timeout handling
- [x] Comprehensive error handling and recovery
- [x] Metrics collection and event parsing
- [x] Background output processor
- [x] Integration testing suite (76 tests)

**Implementation Approach:**
```bash
# Actual implementation using claude -p
claude -p "Initial prompt" \
  --session-id "$session_id" \
  --output-format stream-json \
  --append-system-prompt-file "$bootstrap_file" \
  --allowedTools "Bash,Read,Edit,Write,Glob,Grep,mcp__serena__*" \
  --max-turns 50 \
  --max-budget-usd 10.00 \
  --verbose
```

**Deliverables:**
- Production-ready agent spawning âœ…
- Complete session lifecycle tracking âœ…
- Real-time monitoring with stream-JSON âœ…
- Comprehensive metrics collection âœ…
- Background output processing âœ…
- 76 integration tests (all passing) âœ…
- Complete documentation suite âœ…

**Actual Effort:** 8 days (research + implementation + testing)
**Completion Date:** 2026-01-27

### ðŸ”œ Phase 3: Parallel Agent Support (NEXT)

**Goal:** Run N concurrent agents with lock-free coordination

**Status:** Planning complete, ready for implementation (2026-01-28)

**Key Design:** Lock-free coordination via atomic filesystem operations
- Atomic work claiming via hard links (`ln` command)
- Git worktree isolation per agent
- Filesystem-based state tracking
- Zero shared mutable state

**Tasks:**
1. [ ] Implement atomic work claim mechanism
2. [ ] Git worktree setup per agent
3. [ ] Agent worker process script
4. [ ] Parallel coordinator (`parallel-loop.sh`)
5. [ ] Health monitoring daemon
6. [ ] Agent pool management (scale up/down)
7. [ ] Stale work detection and reclamation
8. [ ] Failure isolation and recovery
9. [ ] Status aggregation across agents
10. [ ] Integration testing (parallel scenarios)

**Architecture Highlights:**
- Lock-free work queue with atomic claims
- Complete agent isolation (worktrees + state dirs)
- Heartbeat-based health monitoring
- Graceful failure handling with work reclamation
- Resource limits per agent (ulimit)
- Observable operation (aggregate status)

**Deliverables:**
- Parallel coordinator working
- N agents running concurrently
- Work stealing disabled (simple pull model)
- Agent failure recovery
- Aggregate status dashboard
- Performance benchmarks (throughput scaling)

**Estimated Effort:** 4 weeks
**Target Throughput:** 2.5x with 3 agents (allowing 17% overhead)

**Documentation:**
- `docs/research/parallel-coordination-design.md` - Complete technical design (1,818 lines)
- `docs/PHASE-3-PLAN.md` - Implementation plan with architecture and integration approach
- `docs/PHASE-3-MILESTONES.md` - Week-by-week breakdown with tasks and acceptance criteria
- `docs/PHASE-3-TESTING.md` - Comprehensive testing strategy (~60 tests planned)
- `docs/PHASE-3-RISKS.md` - Risk analysis with mitigation and contingency plans

### ðŸ”œ Phase 4: Knowledge & Documentation (PLANNED)

**Goal:** Complete knowledge preservation and discovery

**Tasks:**
1. [ ] Document template system
2. [ ] Automated research preservation
3. [ ] Enhanced Serena memory integration
4. [ ] Session summary generation
5. [ ] Knowledge indexing and search
6. [ ] Cross-session knowledge graph

**Features:**
- Auto-generate session summaries from transcripts
- Preserve research automatically to docs/research/
- Index documentation for quick discovery
- Link related sessions and findings
- Agent-readable knowledge base

**Deliverables:**
- Documentation templates
- Auto-preservation hooks in loop
- Enhanced Serena integration
- Knowledge discovery tools
- Session summary generator

**Estimated Effort:** 3-4 days

### ðŸ”œ Phase 5: Work Orchestration (PLANNED)

**Goal:** Intelligent work routing and tracking

**Tasks:**
1. [ ] Enhanced work queue with prioritization
2. [ ] Rig-aware dispatching (work affinity)
3. [ ] Convoy integration for batch tracking
4. [ ] Dependency-aware scheduling
5. [ ] Work item retry logic
6. [ ] Priority-based scheduling

**Features:**
- Smart work routing to appropriate rigs
- Priority-based scheduling (high/medium/low)
- Convoy-based batch tracking
- Work affinity (agents prefer same rig)
- Failed work retry with backoff
- Dependency tracking

**Deliverables:**
- Intelligent queue manager
- Rig dispatcher with affinity
- Convoy tracking integration
- Retry and failure handling
- Work dependency tracker

**Estimated Effort:** 4-5 days

### ðŸ”œ Phase 6: Advanced Monitoring (PLANNED)

**Goal:** Comprehensive observability and control

**Tasks:**
1. [ ] Enhanced metrics collection system
2. [ ] Web dashboard (optional)
3. [ ] Real-time status updates with WebSocket
4. [ ] Alert system (Slack/email)
5. [ ] Performance analytics and trends
6. [ ] Prometheus/Grafana integration

**Features:**
- Real-time metrics (iterations/hour, success rate, throughput)
- Web-based status dashboard with live updates
- Slack/email notifications for interrupts
- Performance tracking over time
- Historical analytics and trends
- Alert manager integration

**Deliverables:**
- Metrics database (time-series)
- Status dashboard (web or TUI)
- Notification system (Slack, email)
- Analytics reports and graphs
- Prometheus exporter
- Grafana dashboards

**Estimated Effort:** 5-7 days

## Current Focus: Phase 3

### Immediate Next Steps

1. **Implement Atomic Work Claims**
   - Update `manage-queue.sh` with hard link mechanism
   - Test claim contention (10 parallel attempts â†’ 1 success)
   - Verify no race conditions under load

2. **Git Worktree Isolation**
   - Implement `setup_agent_worktree()` function
   - Test concurrent agent operations
   - Verify git isolation (commits don't conflict)

3. **Build Agent Worker Script**
   - Create `scripts/spawn-agent-worker.sh`
   - Implement agent lifecycle (claim â†’ work â†’ release)
   - Add heartbeat mechanism
   - Test resource limits

4. **Parallel Coordinator**
   - Create `parallel-loop.sh` main coordinator
   - Implement agent pool management
   - Build health monitoring
   - Test scale-up/scale-down

5. **Integration Testing**
   - Test 1 agent (baseline)
   - Test 3 agents (target config)
   - Test 10 agents (stress)
   - Measure throughput gains
   - Validate failure recovery

### Key Design Decisions (From Phase 2)

**âœ… CLI Invocation:** Use `claude -p` with `--output-format stream-json`

**âœ… Prompt Injection:** Use `--append-system-prompt-file` to preserve Claude Code defaults

**âœ… Session Monitoring:** Parse stream-JSON events in real-time via background processor

**âœ… Context Injection:** Template substitution in bootstrap.md (sed-based)

**âœ… Completion Detection:** Process exit code + exit file capture

**âœ… Output Capture:** Dual streams (stdout for events, stderr for errors) + Claude transcript

## Dependencies & Blockers

### Current Blockers

None - Phase 2 complete

### Phase 3 Dependencies

- Git worktree support (available in git 2.5+)
- Atomic filesystem operations (ln hard links)
- Sufficient disk space for N worktrees (~500MB each)

### Technical Debt Resolved in Phase 2

- âœ… `spawn_agent()` now production-ready
- âœ… Real-time session monitoring implemented
- âœ… Complete output capture (stream-JSON + transcript)
- âœ… Comprehensive error recovery

### New Technical Considerations

- Parallel git operations may contend on remote
- Coordinator single point of failure (mitigated by crash recovery)
- Filesystem limits on open files (check ulimit)
- Disk space management for worktrees

## Testing Strategy

### Phase 1 Testing âœ…

- [x] Loop structure executes
- [x] Queue management works
- [x] Interrupt detection functions
- [x] Context preservation saves files
- [x] Status reporting displays correctly

### Phase 2 Testing âœ…

- [x] Agent spawning executes Claude Code (76 tests)
- [x] Bootstrap prompt is delivered and substituted
- [x] Session runs and completes successfully
- [x] Output is captured (stream-JSON + transcript)
- [x] State is preserved correctly across lifecycle
- [x] Real-time monitoring detects all events
- [x] Error scenarios handled gracefully
- [x] Timeout and stall detection working
- [x] Heartbeat mechanism functional
- [x] Metrics collection accurate

**Test Coverage:**
- 7 test suites
- 76 integration tests
- All tests passing
- 4,560 lines of test code
- Mock Claude CLI for isolation
- 45+ live test iterations validated

### Phase 3 Testing Plan

- [ ] Atomic claim mechanism (race condition tests)
- [ ] Worktree isolation (concurrent git operations)
- [ ] Agent worker lifecycle (spawn â†’ work â†’ terminate)
- [ ] Health monitoring (heartbeat, stall, crash detection)
- [ ] Parallel coordinator (N agents simultaneously)
- [ ] Failure recovery (agent crash, work reclamation)
- [ ] Throughput scaling (1 vs 3 vs 10 agents)
- [ ] 24-hour stability test

### Integration Testing Plan

- [x] End-to-end workflow (queue â†’ spawn â†’ work â†’ complete)
- [x] Interrupt and resume cycle
- [x] Knowledge preservation across sessions
- [x] Multi-iteration continuity
- [ ] Parallel agent coordination (Phase 3)
- [ ] High contention scenarios (Phase 3)
- [ ] Coordinator crash recovery (Phase 3)

## Metrics & Success Criteria

### Phase 1 Success âœ…

- Loop runs without crashing
- Queue can be managed
- Interrupts are detected
- Context is preserved
- Status is visible

### Phase 2 Success âœ…

- âœ… Agents spawn successfully (100% success rate in tests)
- âœ… Work is executed by agents (real Claude Code integration)
- âœ… Sessions complete and cleanup (proper lifecycle)
- âœ… Logs are captured (stream-JSON + transcript)
- âœ… State persists correctly (filesystem audit trail)
- âœ… Real-time monitoring provides visibility
- âœ… Error handling gracefully recovers
- âœ… Timeout detection prevents runaway sessions
- âœ… Heartbeat mechanism tracks liveness
- âœ… Metrics collection accurate

**Measured Performance (Phase 2):**
- Session spawn time: ~2 seconds
- Test suite runtime: <5 minutes (76 tests)
- Mock agent overhead: <1%
- State file I/O: negligible
- Monitoring latency: <1 second

### Phase 3 Success Criteria

- N agents run concurrently without conflicts
- Atomic work claims have zero race conditions
- Git worktrees isolate agent operations
- Agent failures recover automatically
- Work is reclaimed from dead agents
- Throughput scales near-linearly (2.5x for 3 agents)
- System runs 24+ hours without intervention
- Coordinator crash recovery works

### Overall Success Criteria

- Runs continuously for 24+ hours without intervention
- Agents complete work successfully (>80% success rate)
- Knowledge accumulates over time in docs/research/
- Interrupts are timely and appropriate (<5min detection)
- Human intervention is minimal (<1 per day)
- Work progresses across rigs (multi-rig support)
- Throughput improves with parallel agents

## Risk Assessment

### High Risk

1. **Claude Code Integration** - Unknown API/CLI capabilities
   - Mitigation: Research thoroughly, start simple, iterate

2. **Session Management** - Complex lifecycle, state tracking
   - Mitigation: Robust error handling, state preservation

### Medium Risk

1. **Performance** - Resource usage with continuous operation
   - Mitigation: Monitoring, limits, optimization

2. **Error Recovery** - Graceful handling of failures
   - Mitigation: Comprehensive error cases, testing

### Low Risk

1. **Configuration** - YAML parsing, validation
   - Mitigation: Schema validation, defaults

2. **Documentation** - Keeping docs in sync
   - Mitigation: Documentation as code, reviews

## Timeline Estimate

**Original Estimate:** 4-5 weeks
**Actual Progress:** Ahead of schedule

- Phase 1: âœ… Complete (1 week) - Completed 2026-01-20
- Phase 2: âœ… Complete (8 days) - Completed 2026-01-27 (originally estimated 2-3 days)
- Phase 3: 4 weeks (in progress - parallel agents)
- Phase 4: 3-4 days (knowledge & documentation)
- Phase 5: 4-5 days (work orchestration)
- Phase 6: 5-7 days (advanced monitoring)

**Minimum Viable Product:** End of Phase 3 (~5 weeks from start)
**Full Featured:** End of Phase 6 (~8-9 weeks from start)
**Current Date:** 2026-01-27

**Next Milestone:** Phase 3 completion (parallel agent support) - Target: 2026-02-24

## Resources & References

### Documentation

- [Claude Harness Workflow](../docs/CLAUDE-HARNESS-WORKFLOW.md) - Full implementation guide
- [Gastown Guide](../GASTOWN-CLAUDE.md) - System overview
- [Agent Instructions](../AGENTS.md) - Basic workflow

### Tools & Dependencies

- Gastown (`gt`) - v0.4.0
- Beads (`bd`) - v0.47.1
- Claude Code CLI - TBD version
- jq - 1.6+
- git - 2.x

### External Resources

- Claude Code documentation
- Ralph Wiggum loop pattern
- Multi-agent orchestration patterns

## Notes & Learnings

### Design Decisions

1. **Shell-based loop** - Simple, debuggable, integrates with existing tools âœ…
2. **File-based state** - JSON files for persistence, easy to inspect âœ…
3. **Interrupt mechanism** - File-based signaling, simple and reliable âœ…
4. **Minimal bootstrap** - Agents build context as needed, efficient âœ…
5. **Stream-JSON monitoring** - Real-time visibility, parseable events âœ… (Phase 2)
6. **Background processors** - Non-blocking output monitoring âœ… (Phase 2)
7. **Atomic operations** - Lock-free coordination via hard links âœ… (Phase 3 design)

### Lessons Learned

1. **Keep it simple** - Complex systems fail, simple systems work
2. **File-based signaling** - Robust and debuggable
3. **Document early** - Helps future agents and humans
4. **Test incrementally** - Don't build too much before testing
5. **Research pays off** - Week spent on CLI research saved implementation time (Phase 2)
6. **Mock for isolation** - Mock Claude CLI enables fast, reliable testing
7. **Stream-JSON is powerful** - Real-time event monitoring without polling
8. **Background processing works** - Non-blocking output capture critical for monitoring

### Questions Resolved (Phase 2)

1. âœ… How to integrate with Claude Code? â†’ `claude -p` with stream-JSON
2. âœ… How to inject bootstrap? â†’ `--append-system-prompt-file` with sed substitution
3. âœ… How to monitor progress? â†’ Parse stream-JSON events + heartbeat mechanism
4. âœ… How to handle crashes? â†’ Exit code capture + graceful recovery
5. âœ… What interval for interrupts? â†’ 30 seconds (configurable)
6. âœ… How to measure success? â†’ Exit code + metrics collection

### Open Questions (Phase 3+)

1. Optimal agent count for throughput vs cost?
2. How to handle git push contention with N agents?
3. Work stealing vs simple pull model?
4. Should coordinator be multi-threaded?
5. How to prevent disk exhaustion from worktrees?

---

**Next Review:** After Phase 2 completion
**Last Updated:** 2026-01-27
**Maintainer:** Eric Friday (via Claude)
